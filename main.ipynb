{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devon Murray\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singapore:\n",
      " count     7907.000000\n",
      "mean       169.332996\n",
      "std        340.187599\n",
      "min          0.000000\n",
      "25%         65.000000\n",
      "50%        124.000000\n",
      "75%        199.000000\n",
      "max      10000.000000\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "NY:\n",
      " count    48895.000000\n",
      "mean       152.720687\n",
      "std        240.154170\n",
      "min          0.000000\n",
      "25%         69.000000\n",
      "50%        106.000000\n",
      "75%        175.000000\n",
      "max      10000.000000\n",
      "Name: price, dtype: float64 \n",
      "\n",
      "Madrid:\n",
      " count    19618.000000\n",
      "mean       129.271740\n",
      "std        484.143545\n",
      "min          0.000000\n",
      "25%         35.000000\n",
      "50%         58.000000\n",
      "75%        100.000000\n",
      "max       9999.000000\n",
      "Name: price, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import preprocessor_improved as prep_improved\n",
    "import preprocessor_baseline as prep_baseline\n",
    "from random_forest_regressor import random_forest_regressor\n",
    "from linear_regression import linear_regression\n",
    "from gbm import xg_boost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "singapore_df = pd.read_csv('datasets/singapore_listings.csv')\n",
    "ny_df = pd.read_csv('datasets/newyorkcity_listings.csv')\n",
    "madrid_df = pd.read_csv('datasets/madrid_listings.csv')\n",
    "\n",
    "\n",
    "# Checking the first few rows of each dataset to understand their structure\n",
    "\n",
    "singapore_description = singapore_df.describe()\n",
    "ny_description = ny_df.describe()\n",
    "madrid_description = madrid_df.describe()\n",
    "\n",
    "print(\"Singapore:\\n\", singapore_description['price'],\"\\n\")\n",
    "print(\"NY:\\n\",ny_description['price'], \"\\n\")\n",
    "print(\"Madrid:\\n\",madrid_description['price'], \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Devon Murray\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py\", line 2150, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Central Region'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 30\u001b[0m\n\u001b[0;32m     22\u001b[0m parametrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: n_estimators,\n\u001b[0;32m     23\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: max_features,\n\u001b[0;32m     24\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: max_depth,\n\u001b[0;32m     25\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: min_samples_split,\n\u001b[0;32m     26\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: min_samples_leaf,\n\u001b[0;32m     27\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: bootstrap}\n\u001b[0;32m     29\u001b[0m rnd_search_cv \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(model, parametrs, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m rnd_search_cv\u001b[38;5;241m.\u001b[39mfit(singapore_X_train, singapore_y_train)\n\u001b[0;32m     32\u001b[0m predictions \u001b[38;5;241m=\u001b[39m rnd_search_cv\u001b[38;5;241m.\u001b[39mpredict(singapore_X_test)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#Mean Absolute Error \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1806\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1807\u001b[0m         ParameterSampler(\n\u001b[0;32m   1808\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1809\u001b[0m         )\n\u001b[0;32m   1810\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 348, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 621, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1147, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 917, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 380, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Devon Murray\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py\", line 2150, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Central Region'\n\n--------------------------------------------------------------------------------\n35 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n    estimator._validate_params()\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preprocess the data\n",
    "singapore_preproccessor, singapore_X, singapore_y = prep_baseline.preprocess_data(singapore_df)\n",
    "ny_preproccessor, ny_X, ny_y = prep_baseline.preprocess_data(ny_df)\n",
    "madrid_preproccessor, madrid_X, madrid_y = prep_baseline.preprocess_data(madrid_df)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test = train_test_split(singapore_X, singapore_y, test_size=0.3, random_state=42)\n",
    "ny_X_train, ny_X_test, ny_y_train, ny_y_test = train_test_split(ny_X, ny_y, test_size=0.3, random_state=42)\n",
    "madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test = train_test_split(madrid_X, madrid_y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#Regression models for each city\n",
    "\n",
    "# Singapore\n",
    "rf_rsme, rf_mae, rf_variance = random_forest_regressor(singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test, singapore_preproccessor)\n",
    "lr_rsme, lr_mae, lr_variance = linear_regression(singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test, singapore_preproccessor)\n",
    "xg_rsme, xg_mae, xg_variance = xg_boost(singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test, singapore_preproccessor)\n",
    "\n",
    "print(\"Singapore\")\n",
    "print(f'Random Forest Regressor RMSE: {rf_rsme}, MAE: {rf_mae}', f'Variance: {rf_variance}')\n",
    "print(f'Linear Regression RMSE: {lr_rsme}, MAE: {lr_mae}', f'Variance: {lr_variance}')\n",
    "print(f'XGBoost RMSE: {xg_rsme}, MAE: {xg_mae}', f'Variance: {xg_variance}')\n",
    "\n",
    "\n",
    "\n",
    "# New York\n",
    "rf_rsme, rf_mae, rf_variance = random_forest_regressor(ny_X_train, ny_X_test, ny_y_train, ny_y_test, ny_preproccessor)\n",
    "lr_rsme, lr_mae, lr_variance = linear_regression(ny_X_train, ny_X_test, ny_y_train, ny_y_test, ny_preproccessor)\n",
    "xg_rsme, xg_mae, xg_variance = xg_boost(ny_X_train, ny_X_test, ny_y_train, ny_y_test, ny_preproccessor)\n",
    "\n",
    "\n",
    "print(\"\\nNew York\")\n",
    "print(f'Random Forest Regressor RMSE: {rf_rsme}, MAE: {rf_mae}', f'Variance: {rf_variance}')\n",
    "print(f'Linear Regression RMSE: {lr_rsme}, MAE: {lr_mae}', f'Variance: {lr_variance}')\n",
    "print(f'XGBoost RMSE: {xg_rsme}, MAE: {xg_mae}', f'Variance: {xg_variance}')\n",
    "\n",
    "\n",
    "# Madrid\n",
    "rf_rsme, rf_mae, rf_variance = random_forest_regressor(madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test, madrid_preproccessor)\n",
    "lr_rsme, lr_mae, lr_variance = linear_regression(madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test, madrid_preproccessor)\n",
    "xg_rsme, xg_mae, xg_variance = xg_boost(madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test, madrid_preproccessor)\n",
    "\n",
    "print(\"\\nMadrid\")\n",
    "print(f'Random Forest Regressor RMSE: {rf_rsme}, MAE: {rf_mae}', f'Variance: {rf_variance}')\n",
    "print(f'Linear Regression RMSE: {lr_rsme}, MAE: {lr_mae}', f'Variance: {lr_variance}')\n",
    "print(f'XGBoost RMSE: {xg_rsme}, MAE: {xg_mae}', f'Variance: {xg_variance}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7907 entries, 0 to 7906\n",
      "Data columns (total 15 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   neighbourhood_group             7907 non-null   object        \n",
      " 1   neighbourhood                   7907 non-null   object        \n",
      " 2   latitude                        7907 non-null   float64       \n",
      " 3   longitude                       7907 non-null   float64       \n",
      " 4   room_type                       7907 non-null   object        \n",
      " 5   minimum_nights                  7907 non-null   int64         \n",
      " 6   number_of_reviews               7907 non-null   int64         \n",
      " 7   last_review                     5149 non-null   datetime64[ns]\n",
      " 8   reviews_per_month               5149 non-null   float64       \n",
      " 9   calculated_host_listings_count  7907 non-null   int64         \n",
      " 10  availability_365                7907 non-null   int64         \n",
      " 11  year                            7907 non-null   float64       \n",
      " 12  month                           7907 non-null   float64       \n",
      " 13  day                             7907 non-null   float64       \n",
      " 14  weekday                         7907 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(4), object(3)\n",
      "memory usage: 926.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7907x58 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 79070 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singapore_X.info()\n",
    "singapore_transformed = singapore_preproccessor.fit_transform(singapore_X)\n",
    "singapore_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m madrid_preproccessor, madrid_X, madrid_y \u001b[38;5;241m=\u001b[39m prep_improved\u001b[38;5;241m.\u001b[39mpreprocess_data(madrid_df)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test \u001b[38;5;241m=\u001b[39m train_test_split(singapore_X, singapore_y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     10\u001b[0m ny_X_train, ny_X_test, ny_y_train, ny_y_test \u001b[38;5;241m=\u001b[39m train_test_split(ny_X, ny_y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test \u001b[38;5;241m=\u001b[39m train_test_split(madrid_X, madrid_y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2619\u001b[0m )\n\u001b[0;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2277\u001b[0m     )\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "#Preprocess the data\n",
    "\n",
    "singapore_preproccessor, singapore_X, singapore_y = prep_improved.preprocess_data(singapore_df)\n",
    "ny_preproccessor, ny_X, ny_y = prep_improved.preprocess_data(ny_df)\n",
    "madrid_preproccessor, madrid_X, madrid_y = prep_improved.preprocess_data(madrid_df)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test = train_test_split(singapore_X, singapore_y, test_size=0.3, random_state=42)\n",
    "ny_X_train, ny_X_test, ny_y_train, ny_y_test = train_test_split(ny_X, ny_y, test_size=0.3, random_state=42)\n",
    "madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test = train_test_split(madrid_X, madrid_y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#Regression models for each city\n",
    "\n",
    "# Singapore\n",
    "rf_rsme, rf_mae, rf_variance = random_forest_regressor(singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test, singapore_preproccessor)\n",
    "lr_rsme, lr_mae, lr_variance = linear_regression(singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test, singapore_preproccessor)\n",
    "xg_rsme, xg_mae, xg_variance = xg_boost(singapore_X_train, singapore_X_test, singapore_y_train, singapore_y_test, singapore_preproccessor)\n",
    "\n",
    "\n",
    "print(\"Singapore\")\n",
    "print(f'Random Forest Regressor RMSE: {rf_rsme}, MAE: {rf_mae}', f'Variance: {rf_variance}')\n",
    "print(f'Linear Regression RMSE: {lr_rsme}, MAE: {lr_mae}', f'Variance: {lr_variance}')\n",
    "print(f'XGBoost RMSE: {xg_rsme}, MAE: {xg_mae}', f'Variance: {xg_variance}')\n",
    "\n",
    "\n",
    "\n",
    "# New York\n",
    "rf_rsme, rf_mae, rf_variance = random_forest_regressor(ny_X_train, ny_X_test, ny_y_train, ny_y_test, ny_preproccessor)\n",
    "lr_rsme, lr_mae, lr_variance = linear_regression(ny_X_train, ny_X_test, ny_y_train, ny_y_test, ny_preproccessor)\n",
    "xg_rsme, xg_mae, xg_variance = xg_boost(ny_X_train, ny_X_test, ny_y_train, ny_y_test, ny_preproccessor)\n",
    "\n",
    "\n",
    "print(\"\\nNew York\")\n",
    "print(f'Random Forest Regressor RMSE: {rf_rsme}, MAE: {rf_mae}', f'Variance: {rf_variance}')\n",
    "print(f'Linear Regression RMSE: {lr_rsme}, MAE: {lr_mae}', f'Variance: {lr_variance}')\n",
    "print(f'XGBoost RMSE: {xg_rsme}, MAE: {xg_mae}', f'Variance: {xg_variance}')\n",
    "\n",
    "\n",
    "\n",
    "# Madrid\n",
    "rf_rsme, rf_mae, rf_variance = random_forest_regressor(madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test, madrid_preproccessor)\n",
    "lr_rsme, lr_mae, lr_variance = linear_regression(madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test, madrid_preproccessor)\n",
    "xg_rsme, xg_mae, xg_variance = xg_boost(madrid_X_train, madrid_X_test, madrid_y_train, madrid_y_test, madrid_preproccessor)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nMadrid\")\n",
    "print(f'Random Forest Regressor RMSE: {rf_rsme}, MAE: {rf_mae}', f'Variance: {rf_variance}')\n",
    "print(f'Linear Regression RMSE: {lr_rsme}, MAE: {lr_mae}', f'Variance: {lr_variance}')\n",
    "print(f'XGBoost RMSE: {xg_rsme}, MAE: {xg_mae}', f'Variance: {xg_variance}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improves Preprocessing with (HyperParameter tuning , grid search , kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
